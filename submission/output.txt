Output for decision tree training algorithm without pruning - Clean data
Average confusion matrix: 
 [[52.4  0.   0.   0.6]
 [ 0.  45.4  2.2  0. ]
 [ 0.2  2.  45.8  0.3]
 [ 0.3  0.   0.1 50.7]] 
Average accuracy:  0.9715
Accuracy: 0.9715
Precision: [0.98867925 0.95378151 0.94824017 0.99217221]
Recall: [0.9905482  0.95780591 0.95218295 0.98255814]
Macro averaged precision: 0.9707182837174562
Macro averaged recall: 0.9707738007624055
F1-score: [0.98961284 0.95578947 0.95020747 0.98734177]
Macro averaged F1-score: 0.9707378892549594
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
Output for decision tree training algorithm without pruning - Noisy data
Average confusion matrix: 
 [[38.3  3.3  2.8  4.5]
 [ 2.4 40.2  4.2  2.5]
 [ 4.5  3.6 40.5  3.4]
 [ 3.5  2.9  3.2 40.2]] 
Average accuracy:  0.796
Accuracy: 0.7959999999999999
Precision: [0.78323108 0.81541582 0.77884615 0.80722892]
Recall: [0.78644764 0.804      0.79881657 0.7944664 ]
Macro averaged precision: 0.7961804937135998
Macro averaged recall: 0.7959326524532722
F1-score: [0.78483607 0.80966767 0.78870497 0.80079681]
Macro averaged F1-score: 0.7960013794897356
=========================================================================
Output for decision tree training algorithm with pruning - Clean data
Average confusion matrix: 
 [[49.3         0.          0.11111111  0.08888889]
 [ 0.         48.3         2.          0.        ]
 [ 0.78888889  2.08888889 47.12222222  0.5       ]
 [ 0.32222222  0.          0.43333333 48.94444444]] 
Average accuracy:  0.9635
Accuracy: 0.9683333333333334
Precision: [0.9959596  0.96023857 0.93311331 0.98479767]
Recall: [0.977959   0.95854465 0.94876957 0.98811126]
Macro averaged precision: 0.9685272877044295
Macro averaged recall: 0.968346123011814
F1-score: [0.98687722 0.95939086 0.94087632 0.98645169]
Macro averaged F1-score: 0.9683990223835304
average pre-pruning depth 11.844444444444445
average post-pruning depth 8.533333333333335
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
Output for decision tree training algorithm with pruning - Noisy data
Average confusion matrix: 
 [[44.07777778  1.05555556  2.05555556  2.31111111]
 [ 2.14444444 43.96666667  3.27777778  2.21111111]
 [ 2.14444444  3.43333333 44.62222222  1.8       ]
 [ 2.82222222  0.82222222  2.12222222 41.13333333]] 
Average accuracy:  0.8665
Accuracy: 0.8690000000000001
Precision: [0.89046016 0.85206718 0.85811966 0.87704335]
Recall: [0.86108096 0.89222097 0.85683806 0.86677593]
Macro averaged precision: 0.8694225883410773
Macro averaged recall: 0.869228981683302
F1-score: [0.87552417 0.8716819  0.85747838 0.87187942]
Macro averaged F1-score: 0.8691409669042558
average pre-pruning depth 17.96666666666666
average post-pruning depth 13.977777777777778
=========================================================================